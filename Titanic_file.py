# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DElwk9lwfV51pSGomHRdgjvUs0Ot4gUQ
"""

# Import essential libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# Load the Titanic dataset (replace 'titanic.csv' with your actual file path)
data = pd.read_csv('/content/Titanic-Dataset.csv')

# Display the first few rows
print(data.head())

# Check for missing values
print(data.isnull().sum())

# Fill missing values in 'Age' with the median age
data['Age'].fillna(data['Age'].median(), inplace=True)

# Fill missing values in 'Embarked' with the most common port
data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)

# Drop the 'Cabin' column due to many missing values
data.drop(['Cabin'], axis=1, inplace=True)

# Convert 'Sex' into numerical values
data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})

# Convert 'Embarked' using one-hot encoding
data = pd.get_dummies(data, columns=['Embarked'], drop_first=True)

# Drop unnecessary columns like 'Name' and 'Ticket'
data.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)

# Define features (X) and target variable (y)
X = data.drop('Survived', axis=1)
y = data['Survived']

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Random Forest Classifier
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print(f"Confusion Matrix:\n{conf_matrix}")
print(f"Classification Report:\n{class_report}")

# Count the number of survivors and non-survivors
survival_count = data['Survived'].value_counts()

# Display the results
print(f"Number of people who did not survive: {survival_count[0]}")
print(f"Number of people who survived: {survival_count[1]}")

# Visualize survival distribution
plt.figure(figsize=(6, 4))
sns.countplot(data['Survived'])
plt.title('Survival Distribution')
plt.xlabel('Survived (1 = Yes, 0 = No)')
plt.ylabel('Count')
plt.show()

# Feature importance
importances = model.feature_importances_
features = X.columns
feature_importance_df = pd.DataFrame({'Features': features, 'Importance': importances})

# Sort the features by importance
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Plot the feature importance
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Features', data=feature_importance_df)
plt.title('Feature Importance in Random Forest Model')
plt.show()